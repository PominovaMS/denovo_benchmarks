Bootstrap: docker
# Define the base image to inherit from.
# (e.g. image with a particular python version
# or a particular pytorch/tensorflow version).
From: python:3.10

# Define system variables to provide GPU access within the container.
%environment
    export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH

%files
    # Copy algorithm-related files to a separate dir /algo.
    # Don't change the dir name.
    algorithms/algorithm_name /algo
    algorithms/base /algo/base

%post
	# [Optional] Install system packages
	# (e.g. some base images may need git installation)
		
    # [Optional] Download algorithm-related files
    # (source codes, weights, etc.)
    # All files must be placed within /algo dir.
    cd /algo
    git clone ... 
    
    # [Optional] Install dependencies
    # (pandas is recommended to support parsing dataset tags)
    pip install --no-cache-dir pandas
    # install or build from source the algorithm, etc.
    pip install --no-cache-dir ...
    
%post
	# Make sure make_predictions.sh file is executable.
    chmod +x /algo/make_predictions.sh
    
# Run algorithm and convert outputs.
# Data is expected to be mounted into /algo/data dir.
%runscript
    cd /algo && ./make_predictions.sh data
