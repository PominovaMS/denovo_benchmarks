Bootstrap: docker
From: tensorflow/tensorflow:1.2.0-gpu

# Define system variables to provide GPU access within the container.
%environment
    export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH

%files
    # Copy algorithm-related files to a separate dir /algo.
    # Don't change the dir name.
    algorithms/deepnovo /algo
    algorithms/base /algo/base

%post
    # Install Python packages
    pip install gnupg
    pip install numpy==1.16.6 pandas==0.24.2 
    pip install Cython==3.0.9
    # last stable pyteomics version for py27
    pip install pyteomics==4.7.0
    # SQLAlchemy version for py27
    pip install SQLAlchemy==1.3.24
    pip install lxml==5.0.2
    # last biopython version for py27
    pip install biopython==1.68

    # Download algorithm-related files
    # (source codes, weights, etc.)
    cd /algo
    # Fix batch size bug in deepnovo_main_modules.py
    cp deepnovo_main_modules.py DeepNovo
    # Build DeepNovo from source
    cd DeepNovo && python deepnovo_cython_setup.py build_ext --inplace && cd ..
    
    # # Download algorithm weights
    curl -LRO ftp://massive.ucsd.edu/v01/MSV000081382/peak/DeepNovo/HighResolution/knapsack.npy
    # # Download model checkpoint (change to use other model weights)
    pip install gdown
    gdown --folder -O train.example https://drive.google.com/drive/folders/1pAUISLTeh3HQY8aaqzmpRyBFERxUJ1Lt
    cp train.example/checkpoint ./
    cp train.example/translate.ckpt* ./
    rm -r train.example

%post
    # Make sure make_predictions.sh file is executable.
    chmod +x /algo/make_predictions.sh

# Run algorithm and convert outputs.
# Data is expected to be mounted into /algo/data dir.
%runscript
    cd /algo && ./make_predictions.sh data
