"""
Script to convert predictions from the algorithm output format 
to the common output format.
"""

import sys
sys.path.append("/cmnfs/home/j.lapin/projects/denovo_benchmarks_pa/algorithms")

import argparse
import os
import re
import numpy as np
from tqdm import tqdm
from pyteomics import mgf
from pyteomics.mztab import MzTab
from base import OutputMapperBase


class OutputMapper(OutputMapperBase):
    REPLACEMENTS = [
        ("C+57.021", "C[UNIMOD:4]"),
        # Amino acid modifications.
        ("M+15.995", "M[UNIMOD:35]"),    # Met oxidation
        ("N+0.984", "N[UNIMOD:7]"),     # Asn deamidation
        ("Q+0.984", "Q[UNIMOD:7]"),     # Gln deamidation
        # N-terminal modifications.
        ("+42.011", "[UNIMOD:1]"),      # Acetylation
        ("+43.006", "[UNIMOD:5]"),      # Carbamylation
        ("-17.027", "[UNIMOD:385]"),     # NH3 loss
    ]
    PEP_SPLIT_PATTERN = r"(?<=.)(?=[A-Z])"
    MOD_PATTERN = r"\[UNIMOD:[0-9]+\]"
    N_TERM_MOD_PATTERN = r"^((\[UNIMOD:[0-9]+\])+)" # find N-term modifications
    # handle N-term modifications in the middle of a sequence
    N_TERM_MOD_CODES = ["[1]", "[5]", "[385]"]

    def __init__(self, input_dir: str) -> None:
        """TODO."""
        fnames = [fname for fname in os.listdir(input_dir) if fname.endswith(".mgf")]
        self.file_names = [fname.split(".")[0] for fname in sorted(fnames)]
        self.fn_dict = {j:i+1 for i,j in enumerate(self.file_names)}

        self.title2spec_idx = {fname: [] for fname in self.file_names}

        for fname in self.file_names:
            print(fname, ": get spectrum indices.")

            filename = os.path.join(input_dir, fname + ".mgf")
            spectra = mgf.read(filename)

            self.title2spec_idx[fname] = {
                spectra[i]["params"]["title"]: i
                for i in tqdm(range(len(spectra)))
            }
        return
    
    def _transform_match_n_term_mod(self, match: re.Match) -> str:
        """
        Transform representation of peptide substring matching
        the N-term modification pattern.
        `[n_mod]PEP` -> `[n_mod]-PEP`
        
        Parameters
        ----------
        match : re.Match
            Substring matching the N-term modification pattern.

        Returns
        -------
        transformed_match : str
            Transformed N-term modification pattern representation.
        """
        ptm = match.group(1)
        return f"{ptm}-"
    
    def _parse_scores(self, scores: str) -> list[float]:
        """
        Convert per-token scores from a string of float scores 
        separated by ',' to a list of float numbers.
        """
        scores = scores.split(",")
        scores = list(map(float, scores))
        return scores

    def format_spectrum_id(self, spectrum_id: str) -> str:
        """
        TODO.
        Transform spectrum id generated by the algorithm to the common format
        `filename.scan.scan.charge` -> `filename:spectrum_idx`.
        """

        spectrum_title = spectrum_id
        filename = spectrum_id.split(".")[0]
        spectrum_idx = self.title2spec_idx[filename][spectrum_title]

        spectrum_id = filename + ":" + str(spectrum_idx)
        return spectrum_id
    
    def format_sequence_and_scores(self, sequence, aa_scores):
        """
        Convert peptide sequence to the common output data format
        (ProForma with modifications represented with 
        Unimod accession codes, e.g. M[UNIMOD:35])
        and modify per-token scores if needed.

        This method is only needed if per-token scores have to be modified 
        to correspond the transformed sequence in ProForma format.
        Otherwise use `format_sequence` method instead.

        Parameters
        ----------
        sequence : str
            Peptide sequence in the original algorithm output format.
        aa_scores: str
            String of per-token scores for each token in the sequence.

        Returns
        -------
        transformed_sequence : str
            Peptide sequence in the common output data format.
        transformed_aa_scores: str
            String of per-token scores corresponding to each token
            in the transformed sequence.
        """   
        # direct (token-to-token) replacements
        for repl_args in self.REPLACEMENTS:
            sequence = sequence.replace(*repl_args)

        # format sequence and scores for n-term modifications
        aa_scores = self._parse_scores(aa_scores)

        if re.search(self.N_TERM_MOD_PATTERN, sequence):
            # transform n-term modification notation
            # represent in ProForma delta mass notation [+n_term_mod]-PEP
            sequence = re.sub(self.N_TERM_MOD_PATTERN, self._transform_match_n_term_mod, sequence)
            
            # count non-terminal tokens
            # assume modification is always attached a token or is terminal;
            # then any non-terminal modification does not increase number of tokens
            n_non_term_tokens = len(re.split(
                self.PEP_SPLIT_PATTERN,
                re.sub(self.MOD_PATTERN, "", sequence).strip("-")
            ))
            # number of scores should match number of tokens (+1 for n-term mods token, if any).
            # merge together all scores for n-term modification tokens
            
            n_term_scores, non_term_scores = aa_scores[:-n_non_term_tokens], aa_scores[-n_non_term_tokens:]
            term_score = np.mean(n_term_scores)
            aa_scores = [term_score] + non_term_scores

        # Fix: for cases when n-term modifications are predicted in the middle of a sequence,
        # merge scores for n-term modification token with previous AA token 
        seq_tokens = re.split(self.PEP_SPLIT_PATTERN, sequence.replace("UNIMOD:", ""))
        for i, token in enumerate(seq_tokens):
            if any(token.endswith(n_term_code) for n_term_code in self.N_TERM_MOD_CODES):
                aa_scores[i:i + 2] = [np.mean(aa_scores[i:i + 2])]
        
        aa_scores = self._format_scores(aa_scores)
        return sequence, aa_scores


parser = argparse.ArgumentParser()
parser.add_argument(
    "--output_path", required=True, help="The path to the algorithm predictions file."
)
parser.add_argument(
    "--input_dir", required=True, help="The dir with the input dataset .mgf files.",
)
args = parser.parse_args()

# Read predictions from output file
output_data = MzTab(args.output_path)
output_data = output_data.spectrum_match_table

# Rename columns to the expected column names if needed
output_data = output_data.rename(
    {
        "search_engine_score[1]": "score",
        "spectra_ref": "spectrum_id_",
        "opt_ms_run[1]_aa_scores": "aa_scores",
        'title': 'spectrum_id',
    },
    axis=1,
)

output_data['scans'] = output_data['spectrum_id'].map(lambda x: x.split('.')[-2])

# Get number of tokens
output_data['length'] = output_data['sequence'].map(lambda x: len(x.split(',')))

# Simulate aa_scores
output_data['aa_scores'] = output_data.apply(lambda x: ",".join([str(x['score']),]*x['length']), axis=1)

# Tie comma-separated sequences together
output_data['sequence'] = output_data['sequence'].map(lambda x: x.replace(',', ''))

# Drop rows with NaN predictions
output_data = output_data[
    output_data[["spectrum_id", "sequence", "score", "aa_scores"]].notnull().all(axis=1)
].reset_index(drop=True)

# Transform data to the common output format
output_mapper = OutputMapper(input_dir=args.input_dir)
output_data = output_mapper.format_output(output_data)

# Add scans column
output_data['scans'] = output_data.apply(lambda x: 'F'+str(output_mapper.fn_dict[x['spectrum_id'].split(':')[0]])+':'+x['scans'], axis=1)

# Save processed predictions to outputs.csv
# (the expected name for the algorithm output file)
output_data.to_csv("outputs.csv", index=False)
